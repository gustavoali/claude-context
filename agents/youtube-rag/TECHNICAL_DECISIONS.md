# YouTube RAG MVP - Decisiones T√©cnicas

## üìã Informaci√≥n del Documento

**Versi√≥n:** 1.0
**Fecha:** 2025-01-05
**Tipo:** Architecture Decision Records (ADRs)
**Estado:** Propuestas para Evaluaci√≥n

## üéØ Metodolog√≠a de Decisiones

Este documento utiliza el formato **Architecture Decision Record (ADR)** para documentar decisiones t√©cnicas importantes, incluyendo el contexto, opciones consideradas, decisi√≥n tomada y consecuencias.

---

## ADR-001: Elecci√≥n de Frontend Framework

**Estado:** Propuesta
**Fecha:** 2025-01-05
**Decidido por:** Arquitecto de Soluciones

### Contexto
El proyecto necesita una interfaz web para reemplazar la interacci√≥n actual v√≠a Jupyter Notebook y API REST directa. Se requiere una soluci√≥n que sea:
- R√°pida de implementar
- Mantenible a largo plazo
- Escalable para m√∫ltiples usuarios
- Integrable con el stack Python existente

### Opciones Consideradas

#### Opci√≥n A: Streamlit
**Pros:**
- ‚úÖ Desarrollo ultrarr√°pido (1-2 semanas)
- ‚úÖ Stack Python puro, sin JavaScript
- ‚úÖ Componentes especializados para ML/Data Science
- ‚úÖ Deploy sencillo
- ‚úÖ Integraci√≥n directa con c√≥digo existente

**Contras:**
- ‚ö†Ô∏è Limitaciones de customizaci√≥n UI
- ‚ö†Ô∏è No ideal para aplicaciones muy complejas
- ‚ö†Ô∏è Menos control sobre UX avanzada

#### Opci√≥n B: React + TypeScript
**Pros:**
- ‚úÖ UX moderna y profesional
- ‚úÖ Ecosistema maduro y robusto
- ‚úÖ Escalabilidad real para producci√≥n
- ‚úÖ Control total sobre UI/UX
- ‚úÖ Preparado para funcionalidades complejas

**Contras:**
- ‚ö†Ô∏è Desarrollo m√°s lento (3-4 semanas)
- ‚ö†Ô∏è Requiere expertise en frontend
- ‚ö†Ô∏è Stack splitting (Python + JavaScript)

#### Opci√≥n C: Gradio
**Pros:**
- ‚úÖ Setup inmediato (1 d√≠a)
- ‚úÖ Especializado para demos ML
- ‚úÖ Sharing autom√°tico

**Contras:**
- ‚ö†Ô∏è Muy limitado para aplicaciones reales
- ‚ö†Ô∏è No escalable

### Decisi√≥n
**Estrategia H√≠brida por Fases:**

1. **Fase 1 (MVP Inmediato):** Streamlit
   - Para demostrar valor r√°pidamente
   - Validar funcionalidades con usuarios
   - Permitir iteraci√≥n temprana

2. **Fase 2 (Producto):** React + TypeScript
   - Una vez validadas las funcionalidades
   - Cuando se justifique la inversi√≥n en UX
   - Para escalar a m√∫ltiples usuarios

### Consecuencias
**Positivas:**
- ‚úÖ Time-to-market r√°pido con Streamlit
- ‚úÖ Migraci√≥n gradual sin reescritura completa
- ‚úÖ Aprendizaje del usuario antes de UX final

**Negativas:**
- ‚ö†Ô∏è Doble desarrollo a largo plazo
- ‚ö†Ô∏è Posible technical debt temporal

---

## ADR-002: Arquitectura de Procesamiento As√≠ncrono

**Estado:** Propuesta
**Fecha:** 2025-01-05

### Contexto
El procesamiento actual es s√≠ncrono y bloquea la API durante minutos. Necesitamos soporte para:
- M√∫ltiples usuarios concurrentes
- Procesamiento de videos largos
- Feedback de progreso en tiempo real
- Recovery de fallos

### Opciones Consideradas

#### Opci√≥n A: Celery + Redis
**Pros:**
- ‚úÖ Est√°ndar de facto en Python
- ‚úÖ Excelente monitoring con Flower
- ‚úÖ Soporte para retry autom√°tico
- ‚úÖ Escalabilidad horizontal

**Contras:**
- ‚ö†Ô∏è Complejidad adicional (Redis dependency)
- ‚ö†Ô∏è Setup y configuraci√≥n extra

#### Opci√≥n B: FastAPI BackgroundTasks
**Pros:**
- ‚úÖ Built-in en FastAPI
- ‚úÖ Simple para casos b√°sicos
- ‚úÖ No dependencias externas

**Contras:**
- ‚ö†Ô∏è No persiste entre restarts
- ‚ö†Ô∏è No escalable horizontalmente
- ‚ö†Ô∏è Monitoring limitado

#### Opci√≥n C: Apache Airflow
**Pros:**
- ‚úÖ Workflow orchestration completo
- ‚úÖ UI rica para monitoring
- ‚úÖ Scheduling avanzado

**Contras:**
- ‚ö†Ô∏è Overkill para este caso de uso
- ‚ö†Ô∏è Complejidad muy alta
- ‚ö†Ô∏è Resource intensive

### Decisi√≥n
**Celery + Redis** con implementaci√≥n gradual:

1. **Fase 1:** BackgroundTasks para MVP
2. **Fase 2:** Migraci√≥n a Celery para escalabilidad

### Arquitectura Propuesta
```python
# Task definition
@celery_app.task(bind=True)
def process_video_async(self, video_url, config):
    stages = [
        ('DOWNLOADING', 10),
        ('EXTRACTING_AUDIO', 20),
        ('TRANSCRIBING', 50),
        ('EXTRACTING_FRAMES', 70),
        ('OCR_PROCESSING', 85),
        ('GENERATING_EMBEDDINGS', 95),
        ('INDEXING', 100)
    ]
    
    for stage, progress in stages:
        self.update_state(
            state=stage, 
            meta={'progress': progress}
        )
        # Process stage...
    
    return {'status': 'SUCCESS', 'video_id': result}
```

### Consecuencias
**Positivas:**
- ‚úÖ Procesamiento no-blocking
- ‚úÖ Escalabilidad horizontal
- ‚úÖ Fault tolerance mejorado
- ‚úÖ Progress tracking granular

**Negativas:**
- ‚ö†Ô∏è Complejidad operacional aumenta
- ‚ö†Ô∏è Debugging m√°s complejo

---

## ADR-003: Estrategia de Almacenamiento

**Estado:** Propuesta
**Fecha:** 2025-01-05

### Contexto
Actualmente todo se almacena en filesystem local. Para escalar necesitamos:
- Persistencia confiable de metadatos
- Storage distribuido para media files
- B√∫squedas eficientes en metadatos
- Backup y recovery

### Opciones Consideradas

#### Opci√≥n A: PostgreSQL + MinIO/S3
**Pros:**
- ‚úÖ PostgreSQL: ACID, queries complejas, JSON support
- ‚úÖ MinIO: S3-compatible, self-hosted
- ‚úÖ Separaci√≥n clara: metadatos vs archivos
- ‚úÖ Escalable independientemente

#### Opci√≥n B: MongoDB + GridFS
**Pros:**
- ‚úÖ Document-based, natural para metadatos JSON
- ‚úÖ GridFS para archivos grandes
- ‚úÖ Schema flexibility

**Contras:**
- ‚ö†Ô∏è Menos familiar para equipo SQL
- ‚ö†Ô∏è ACID limitations

#### Opci√≥n C: SQLite + Local Storage
**Pros:**
- ‚úÖ Simplicidad m√°xima
- ‚úÖ Zero-config

**Contras:**
- ‚ö†Ô∏è No escalable
- ‚ö†Ô∏è No concurrency real

### Decisi√≥n
**PostgreSQL + MinIO** con migraci√≥n gradual:

**Esquema de Base de Datos:**
```sql
-- Core entities
CREATE TABLE videos (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    video_id VARCHAR(50) UNIQUE NOT NULL,
    title TEXT NOT NULL,
    description TEXT,
    url TEXT,
    duration INTERVAL,
    status VARCHAR(20) DEFAULT 'processing',
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    metadata JSONB,
    
    -- Indexing for search
    CONSTRAINT valid_status CHECK (status IN ('processing', 'completed', 'failed'))
);

CREATE TABLE text_segments (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    video_id UUID REFERENCES videos(id) ON DELETE CASCADE,
    start_time FLOAT NOT NULL,
    end_time FLOAT NOT NULL,
    content TEXT NOT NULL,
    source VARCHAR(20) DEFAULT 'transcript', -- 'transcript' | 'ocr'
    confidence FLOAT,
    embedding_vector VECTOR(384), -- pgvector extension
    created_at TIMESTAMP DEFAULT NOW(),
    
    -- Indexing
    INDEX idx_video_time (video_id, start_time),
    INDEX idx_content_search USING gin(to_tsvector('spanish', content))
);

CREATE TABLE image_segments (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    video_id UUID REFERENCES videos(id) ON DELETE CASCADE,
    timestamp FLOAT NOT NULL,
    image_path TEXT NOT NULL, -- MinIO path
    thumbnail_path TEXT,
    ocr_content TEXT,
    embedding_vector VECTOR(512), -- CLIP embedding
    created_at TIMESTAMP DEFAULT NOW(),
    
    -- Indexing  
    INDEX idx_video_timestamp (video_id, timestamp)
);

-- Search performance
CREATE INDEX idx_text_embedding ON text_segments USING ivfflat (embedding_vector);
CREATE INDEX idx_image_embedding ON image_segments USING ivfflat (embedding_vector);
```

### Storage Strategy
```
MinIO Buckets:
‚îú‚îÄ‚îÄ videos/           # Original video files
‚îÇ   ‚îî‚îÄ‚îÄ {video_id}.{ext}
‚îú‚îÄ‚îÄ audio/            # Extracted audio
‚îÇ   ‚îî‚îÄ‚îÄ {video_id}.wav
‚îú‚îÄ‚îÄ frames/           # Video frames
‚îÇ   ‚îî‚îÄ‚îÄ {video_id}/
‚îÇ       ‚îú‚îÄ‚îÄ frame_0000.jpg
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ thumbnails/       # Generated thumbnails
    ‚îî‚îÄ‚îÄ {video_id}/
        ‚îú‚îÄ‚îÄ thumb_0000.jpg
        ‚îî‚îÄ‚îÄ ...
```

### Consecuencias
**Positivas:**
- ‚úÖ Escalabilidad real
- ‚úÖ ACID compliance para metadatos
- ‚úÖ S3-compatible storage
- ‚úÖ Rich querying capabilities

**Negativas:**
- ‚ö†Ô∏è Complejidad operacional
- ‚ö†Ô∏è Costo de infraestructura adicional

---

## ADR-004: Vector Search Strategy

**Estado:** Propuesta
**Fecha:** 2025-01-05

### Contexto
FAISS actual funciona pero tiene limitaciones para producci√≥n:
- No persistencia transaccional
- No metadata filtering
- Scaling horizontal limitado
- No integration con SQL queries

### Opciones Consideradas

#### Opci√≥n A: FAISS + PostgreSQL H√≠brido
**Pros:**
- ‚úÖ Mantiene performance actual
- ‚úÖ A√±ade SQL capabilities
- ‚úÖ Metadata filtering eficiente

**Implementaci√≥n:**
```python
class HybridVectorStore:
    def __init__(self):
        self.faiss_index = faiss.IndexFlatIP(dimension)
        self.db = PostgreSQLDB()
    
    async def search(self, query_vector, filters=None, top_k=10):
        # 1. Apply SQL filters first
        candidate_ids = await self.db.get_candidates(filters)
        
        # 2. Vector search on subset
        if candidate_ids:
            subset_vectors = self.get_vectors_by_ids(candidate_ids)
            scores, indices = self.faiss_index.search(query_vector, top_k)
            
        # 3. Enrich with metadata
        return self.enrich_results(scores, indices)
```

#### Opci√≥n B: pgvector Extension
**Pros:**
- ‚úÖ Todo en PostgreSQL
- ‚úÖ ACID transactions
- ‚úÖ SQL queries nativas
- ‚úÖ Metadata filtering natural

**Implementaci√≥n:**
```sql
-- Vector search con metadata filtering
SELECT 
    ts.content,
    ts.start_time,
    ts.end_time,
    v.title,
    (ts.embedding_vector <=> $1) as similarity
FROM text_segments ts
JOIN videos v ON ts.video_id = v.id
WHERE v.status = 'completed'
    AND ts.start_time BETWEEN $2 AND $3
ORDER BY ts.embedding_vector <=> $1
LIMIT $4;
```

#### Opci√≥n C: Weaviate/Qdrant
**Pros:**
- ‚úÖ Purpose-built para vector search
- ‚úÖ Metadata filtering nativo
- ‚úÖ RESTful APIs
- ‚úÖ Escalabilidad horizontal

**Contras:**
- ‚ö†Ô∏è Dependencia externa adicional
- ‚ö†Ô∏è Learning curve

### Decisi√≥n
**Enfoque Evolutivo:**

1. **Fase 1:** FAISS + PostgreSQL h√≠brido
2. **Fase 2:** Migraci√≥n a pgvector puro
3. **Fase 3:** Evaluaci√≥n de Qdrant si se requiere scale masivo

### Implementaci√≥n Propuesta
```python
# Nuevo motor de b√∫squeda h√≠brido
class ProductionRAGEngine:
    def __init__(self):
        self.vector_store = HybridVectorStore()
        self.text_embedder = TextEmbedder()
        self.vision_embedder = CLIPEncoder()
    
    async def search_multimodal(self, 
                               query: str,
                               video_filters: dict = None,
                               time_range: tuple = None,
                               top_k: int = 10):
        
        # Text search
        text_vector = self.text_embedder.encode([query])
        text_results = await self.vector_store.search_text(
            text_vector, 
            filters=video_filters,
            time_range=time_range,
            top_k=top_k
        )
        
        # Image search  
        image_vector = self.vision_embedder.encode_text([query])
        image_results = await self.vector_store.search_images(
            image_vector,
            filters=video_filters,
            time_range=time_range, 
            top_k=min(4, top_k)
        )
        
        return {
            'text_results': text_results,
            'image_results': image_results,
            'combined_score': self._compute_multimodal_score(text_results, image_results)
        }
```

---

## ADR-005: Monitoring y Observabilidad

**Estado:** Propuesta
**Fecha:** 2025-01-05

### Contexto
Para producci√≥n necesitamos visibilidad completa del sistema:
- Performance monitoring
- Error tracking  
- Business metrics
- Health checks
- Alerting

### Decisi√≥n: Stack de Observabilidad

#### Logging: Structured Logging
```python
import structlog
import logging.config

# Configuraci√≥n de logging estructurado
logging.config.dictConfig({
    "version": 1,
    "disable_existing_loggers": False,
    "formatters": {
        "json": {
            "()": structlog.stdlib.ProcessorFormatter,
            "processor": structlog.dev.ConsoleRenderer(colors=False),
        },
    },
    "handlers": {
        "default": {
            "level": "INFO",
            "class": "logging.StreamHandler",
            "formatter": "json",
        },
    },
    "loggers": {
        "": {
            "handlers": ["default"],
            "level": "INFO",
        },
    }
})

logger = structlog.get_logger()

# Usage
logger.info("video_processing_started", 
           video_id=video_id, 
           user_id=user_id,
           duration_estimate=estimated_duration)
```

#### Metrics: Prometheus + Grafana
```python
from prometheus_client import Counter, Histogram, Gauge, Info

# Business metrics
videos_processed = Counter('videos_processed_total', 
                          'Total videos processed', 
                          ['status', 'source'])

processing_duration = Histogram('video_processing_seconds',
                               'Time spent processing videos',
                               ['stage'])

active_jobs = Gauge('active_processing_jobs', 
                   'Number of videos currently being processed')

system_info = Info('youtube_rag_system', 'System information')
```

#### Health Checks
```python
@app.get("/health")
async def health_check():
    checks = {
        "database": await check_database_connection(),
        "redis": await check_redis_connection(),
        "storage": await check_storage_connection(),
        "vector_index": await check_vector_index_health(),
        "worker_queue": await check_worker_queue_health()
    }
    
    all_healthy = all(checks.values())
    status_code = 200 if all_healthy else 503
    
    return Response(
        content=json.dumps({
            "status": "healthy" if all_healthy else "unhealthy",
            "timestamp": datetime.now().isoformat(),
            "checks": checks,
            "version": get_version()
        }),
        status_code=status_code,
        media_type="application/json"
    )
```

---

## üìä Resumen de Decisiones

| ADR | Decisi√≥n | Rationale | Impacto |
|-----|----------|-----------|---------|
| ADR-001 | Streamlit ‚Üí React | Time-to-market vs UX final | Alto |
| ADR-002 | Celery + Redis | Escalabilidad y fault tolerance | Medio |
| ADR-003 | PostgreSQL + MinIO | Datos estructurados + media | Alto |
| ADR-004 | FAISS ‚Üí pgvector | Integraci√≥n SQL + vector search | Medio |
| ADR-005 | Prometheus + Grafana | Observabilidad production-ready | Medio |

## üîÑ Proceso de Revisi√≥n

**Periodicidad:** Revisi√≥n trimestral de ADRs
**Criterios de Revisi√≥n:**
- ¬øLa decisi√≥n sigue siendo v√°lida?
- ¬øHan aparecido mejores alternativas?
- ¬øLas consecuencias fueron las esperadas?
- ¬øRequiere actualizaci√≥n o deprecation?

**Pr√≥xima Revisi√≥n:** 2025-04-05

---

*Decisiones t√©cnicas documentadas el 2025-01-05 como parte del proceso de arquitectura del proyecto YouTube RAG MVP.*